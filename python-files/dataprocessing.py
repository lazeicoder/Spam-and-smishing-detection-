# -*- coding: utf-8 -*-
"""DataProcessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GYVsUXSnppK99fv0EjenBrqWTX_uH73w
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re

df = pd.read_csv(path)

print("Original shape:", df.shape)
print("\nColumns:", df.columns.tolist())
print("\nMissing values per column:\n", df.isna().sum())

num_duplicates = df.duplicated().sum()
print("\nNumber of duplicate rows:", num_duplicates)

df = df.drop_duplicates().reset_index(drop=True)
print("Shape after dropping duplicates:", df.shape)

class_counts = df["LABEL"].value_counts()
class_ratio = class_counts / len(df)

print("\nClass counts:\n", class_counts)
print("\nClass ratios:\n", class_ratio)

binary_map = {"Yes": 1, "No": 0, "YES": 1, "NO": 0}
for col in ["URL", "EMAIL", "PHONE"]:
    df[col] = df[col].map(binary_map)

label_map = {"ham": 0, "smishing": 1}
df["LABEL_ENC"] = df["LABEL"].map(label_map)

def clean_text_basic(text):
    text = text.lower()
    text = re.sub(r"[^a-z0-9\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

df["TEXT_CLEAN"] = df["TEXT"].astype(str).apply(clean_text_basic)

df["CHAR_LEN"] = df["TEXT_CLEAN"].apply(len)
df["WORD_COUNT"] = df["TEXT_CLEAN"].apply(lambda x: len(x.split()))

print("\nText length statistics (overall):")
print(df[["CHAR_LEN", "WORD_COUNT"]].describe())

plt.figure()
class_counts.plot(kind="bar")
plt.title("Class Distribution (Ham vs Smishing)")
plt.xlabel("Class")
plt.ylabel("Number of Samples")
plt.show()

url_by_class = df.groupby("LABEL_ENC")["URL"].mean()
plt.figure()
url_by_class.plot(kind="bar")
plt.title("Average URL Presence by Class")
plt.xlabel("Class (0=Ham, 1=Smishing)")
plt.ylabel("Proportion with URL")
plt.show()

email_by_class = df.groupby("LABEL_ENC")["EMAIL"].mean()
plt.figure()
email_by_class.plot(kind="bar")
plt.title("Average Email Presence by Class")
plt.xlabel("Class (0=Ham, 1=Smishing)")
plt.ylabel("Proportion with Email")
plt.show()

phone_by_class = df.groupby("LABEL_ENC")["PHONE"].mean()
plt.figure()
phone_by_class.plot(kind="bar")
plt.title("Average Phone Presence by Class")
plt.xlabel("Class (0=Ham, 1=Smishing)")
plt.ylabel("Proportion with Phone")
plt.show()

plt.figure()
df["CHAR_LEN"].hist()
plt.title("Distribution of Message Length (Characters)")
plt.xlabel("Number of Characters")
plt.ylabel("Frequency")
plt.show()

plt.figure()
df["WORD_COUNT"].hist()
plt.title("Distribution of Message Length (Words)")
plt.xlabel("Number of Words")
plt.ylabel("Frequency")
plt.show()

numeric_cols = ["URL", "EMAIL", "PHONE", "CHAR_LEN", "WORD_COUNT", "LABEL_ENC"]
corr = df[numeric_cols].corr()

plt.figure()
plt.imshow(corr)
plt.title("Correlation Heatmap")
plt.xticks(range(len(numeric_cols)), numeric_cols, rotation=90)
plt.yticks(range(len(numeric_cols)), numeric_cols)
plt.colorbar()
plt.tight_layout()
plt.show()

print("\nFinal dataset shape:", df.shape)
print("\nCorrelation matrix:\n", corr.round(3))

print("\nPreprocessing completed:")
print("- Duplicates removed")
print("- Binary features encoded (URL, EMAIL, PHONE)")
print("- Labels encoded (ham=0, smishing=1)")
print("- Basic text normalization applied")
print("- Engineered features: CHAR_LEN, WORD_COUNT")
print("- Visualizations generated for class balance, feature distributions, and correlations")
